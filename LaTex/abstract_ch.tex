% 中文摘要

深度学习技术在大数据时代席卷了目标检测、图像分类、自然语言处理、自动驾驶、推荐系统等诸多应用领域，引领现在和将来的技术主流浪潮。
然而，由于数据集规模和神经网络模型复杂度的迅速膨胀，模型训练需要越来越多的计算资源，导致单机训练速度缓慢，甚至无法成功部署。
分布式计算技术能够组织、协同多个计算节点进行网络模型训练，是解决大规模数据场景下复杂模型训练的有效方案。
但分布式训练的迭代过程中，网络拓扑中各节点之间高频、全尺寸全精度的数据通信交换了大量数据，严重拖慢了训练进程，成为分布式算法的关键瓶颈。
针对这一通信瓶颈问题，本文从压缩通信数据和缩减通信频次两个角度出发，
提出了基于近似质心的梯度压缩算法（Gradient Compression via Approximate Centroid，GCAC）和基于$k$-互异近邻的梯度压缩算法（Gradient Compression based on $k$-Reciprocal Nearest neighbors，$k$-RNGC），旨在减小训练过程中的通信开销，优化并加速了分布式训练流程。
本文主要研究内容与创新点具体描述如下：

GCAC算法首先利用加速计算技术得到网络模型中局部梯度张量的近似质心，
然后根据梯度与近似质心之间的距离结合预设的梯度压缩比，筛选出合适的梯度，
保留了模型参数优化所需的关键梯度信息，大幅减少了网络通信流量，加速了分布式训练速度。
实验结果表明，GCAC算法能在不同规模的任务场景中有效加速网络模型收敛、提高分布式训练效率且保证模型性能，尤其在小压缩比时，GCAC算法还可以提高网络模型的最终收敛精度。
但由于GCAC算法在实践过程采用了近似质心的加速计算技术，导致该算法在大压缩比场景下训练小模型时，
模型收敛性和性能表现均有较大下降。

为了克服GCAC算法在大压缩比时的难题，本文从通信数据压缩和通信频次缩减协同的角度出发，
提出了基于$k$-互异近邻的梯度压缩算法。
$k$-RNGC算法首先通过全局梯度计算感知算法获取局部梯度压缩比，
然后基于该局部压缩比使用$k$-互异近邻梯度选择算法进行梯度优选，对原梯度张量进行压缩，大幅度减少了网络通信的数据量。
该算法还融合了动量修正以及预热训练等组件，优化了分布式训练流程。
高光谱目标检测和图像分类等实验结果表明，在100倍压缩比的情况下，$k$-RNGC算法不仅具有良好的模型和数据适应能力、克服了GACA所面临的大压缩比问题，还能够有效提高分布式训练效率。
